{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# global functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_nan(data):\n",
    "    data2 = data.fillna(\" \")\n",
    "    return data2\n",
    "\n",
    "def wordopt(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub(\"\\\\W\",\" \",text) \n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)  \n",
    "    return text\n",
    "\n",
    "# remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "#nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "ps = PorterStemmer()\n",
    "def stemming(text):\n",
    "    text = re.sub('[^a-zA-Z]',' ',text)\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    text = [ps.stem(word) for word in text if not word in stopwords.words('english')]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "def namestr(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read file and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "predict = pd.read_csv(\"predict.csv\")\n",
    "\n",
    "train = train[0:1000]\n",
    "predict = predict[0:1000]\n",
    "\n",
    "train = handle_nan(train)\n",
    "predict = handle_nan(predict)\n",
    "\n",
    "x = train['text'].apply(wordopt)\n",
    "y = train['label']\n",
    "p = predict['text'].apply(wordopt)\n",
    "\n",
    "#x = train['text'].apply(stemming)\n",
    "#p = predict['text'].apply(stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn prepare functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "vectorization = CountVectorizer()\n",
    "x_train = vectorization.fit_transform(x_train)\n",
    "x_test = vectorization.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_testing(model, news):\n",
    "    testing_news = {\"text\":[news]}\n",
    "    new_def_test = pd.DataFrame(testing_news)\n",
    "    new_x_test = new_def_test[\"text\"]\n",
    "    new_x_test = vectorization.transform(new_x_test)\n",
    "    return \"proba of 0 & 1:\", model.predict_proba(new_x_test)\n",
    "\n",
    "def preciction(model, data):\n",
    "    model_name = namestr(model,globals())[0]\n",
    "    new_def_test = p\n",
    "    new_x_test = vectorization.transform(new_def_test)\n",
    "\n",
    "    predictions_test = pd.DataFrame(model.predict(new_x_test))\n",
    "    predictions_test_predict_proba = pd.DataFrame(model.predict_proba(new_x_test))\n",
    "    test_id = pd.DataFrame(predict[\"id\"])\n",
    "\n",
    "    submission = pd.concat([test_id, predictions_test, predictions_test_predict_proba],axis=1)\n",
    "    submission.columns = [\"id\",model_name,\"proba_0\",\"proba_1\"]\n",
    "    submission.to_csv(\"out_{}.csv\".format(model_name),index=False)\n",
    "\n",
    "def cross_val(model):\n",
    "    scores = cross_val_score(model, x_train,y_train, scoring=\"neg_mean_squared_error\", cv=2)\n",
    "    tree_rmse_scores = np.sqrt(-scores)\n",
    "    return (\"Scores:\", scores),(\"Mean:\", scores.mean()),(\"Standard deviation:\", scores.std())\n",
    "\n",
    "def Confusion_Matrix_f1_score(model):    \n",
    "    y_train_pred = cross_val_predict(model, x_train,y_train, cv=3)\n",
    "    return confusion_matrix(y_train,y_train_pred), f1_score(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare different sklearn algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "Bayesian = MultinomialNB()\n",
    "Bayesian.fit(x_train,y_train)\n",
    "Bayesian.score(x_test, y_test)\n",
    "Confusion_Matrix_f1_score(Bayesian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preciction(Bayesian,p)\n",
    "manual_testing(Bayesian, str(\"Not quite all the action is  . Peter Thiel, a founder of PayPal and Palantir who was the first outside investor in Facebook, spoke at the Republican convention in July. The New York Times reported on Saturday that Mr. Thiel is giving $1. 25 million to support Mr. Trump’s candidacy even as other supporters flee. (He also recently gave $1 million to a “super PAC” that supports Senator Rob Portman, the Republican freshman running for   in Ohio.) Getting involved in politics used to be seen as clashing with Silicon Valley’s value system: You transform the world by making problems obsolete, not solving them through Washington. Nor did entrepreneurs want to alienate whatever segment of customers did not agree with them politically. Such reticence is no longer in style here. “We’re a bunch of nerds not used to having a lot of limelight,” said Dave McClure, an investor who runs a tech incubator called 500 Startups.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Logistic = LogisticRegression()\n",
    "Logistic.fit(x_train,y_train)\n",
    "Confusion_Matrix_f1_score(Logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preciction(Logistic,p)\n",
    "manual_testing(Logistic, str(\"Not quite all the action is  . Peter Thiel, a founder of PayPal and Palantir who was the first outside investor in Facebook, spoke at the Republican convention in July. The New York Times reported on Saturday that Mr. Thiel is giving $1. 25 million to support Mr. Trump’s candidacy even as other supporters flee. (He also recently gave $1 million to a “super PAC” that supports Senator Rob Portman, the Republican freshman running for   in Ohio.) Getting involved in politics used to be seen as clashing with Silicon Valley’s value system: You transform the world by making problems obsolete, not solving them through Washington. Nor did entrepreneurs want to alienate whatever segment of customers did not agree with them politically. Such reticence is no longer in style here. “We’re a bunch of nerds not used to having a lot of limelight,” said Dave McClure, an investor who runs a tech incubator called 500 Startups.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DecisionTree = DecisionTreeClassifier()\n",
    "DecisionTree.fit(x_train,y_train)\n",
    "Confusion_Matrix_f1_score(DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preciction(DecisionTree,p)\n",
    "manual_testing(DecisionTree, str(\"Not quite all the action is  . Peter Thiel, a founder of PayPal and Palantir who was the first outside investor in Facebook, spoke at the Republican convention in July. The New York Times reported on Saturday that Mr. Thiel is giving $1. 25 million to support Mr. Trump’s candidacy even as other supporters flee. (He also recently gave $1 million to a “super PAC” that supports Senator Rob Portman, the Republican freshman running for   in Ohio.) Getting involved in politics used to be seen as clashing with Silicon Valley’s value system: You transform the world by making problems obsolete, not solving them through Washington. Nor did entrepreneurs want to alienate whatever segment of customers did not agree with them politically. Such reticence is no longer in style here. “We’re a bunch of nerds not used to having a lot of limelight,” said Dave McClure, an investor who runs a tech incubator called 500 Startups.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k_neighbor = KNeighborsClassifier()\n",
    "k_neighbor.fit(x_train,y_train)\n",
    "Confusion_Matrix_f1_score(k_neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preciction(k_neighbor,p)\n",
    "manual_testing(k_neighbor, str(\"Not quite all the action is  . Peter Thiel, a founder of PayPal and Palantir who was the first outside investor in Facebook, spoke at the Republican convention in July. The New York Times reported on Saturday that Mr. Thiel is giving $1. 25 million to support Mr. Trump’s candidacy even as other supporters flee. (He also recently gave $1 million to a “super PAC” that supports Senator Rob Portman, the Republican freshman running for   in Ohio.) Getting involved in politics used to be seen as clashing with Silicon Valley’s value system: You transform the world by making problems obsolete, not solving them through Washington. Nor did entrepreneurs want to alienate whatever segment of customers did not agree with them politically. Such reticence is no longer in style here. “We’re a bunch of nerds not used to having a lot of limelight,” said Dave McClure, an investor who runs a tech incubator called 500 Startups.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14 min to run\n",
    "from sklearn.svm import SVC\n",
    "SVC1 = SVC()\n",
    "SVC1.fit(x_train,y_train)\n",
    "Confusion_Matrix_f1_score(SVC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#33 min to run\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp  = MLPClassifier(solver='lbfgs', activation='logistic')\n",
    "mlp.fit(x_train,y_train)\n",
    "Confusion_Matrix_f1_score(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preciction(mlp,p)\n",
    "manual_testing(mlp, str(\"Not quite all the action is  . Peter Thiel, a founder of PayPal and Palantir who was the first outside investor in Facebook, spoke at the Republican convention in July. The New York Times reported on Saturday that Mr. Thiel is giving $1. 25 million to support Mr. Trump’s candidacy even as other supporters flee. (He also recently gave $1 million to a “super PAC” that supports Senator Rob Portman, the Republican freshman running for   in Ohio.) Getting involved in politics used to be seen as clashing with Silicon Valley’s value system: You transform the world by making problems obsolete, not solving them through Washington. Nor did entrepreneurs want to alienate whatever segment of customers did not agree with them politically. Such reticence is no longer in style here. “We’re a bunch of nerds not used to having a lot of limelight,” said Dave McClure, an investor who runs a tech incubator called 500 Startups.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "#Deep learning libraries\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_predict_tf(model_name, str):\n",
    "    data = []\n",
    "    data.append(pred)\n",
    "    p2 = pd.DataFrame(data)\n",
    "\n",
    "    p2 = p2[0].apply(wordopt)\n",
    "\n",
    "    tokenizer_p = Tokenizer(num_words = voc_size)\n",
    "    tokenizer_p.fit_on_texts(p2)\n",
    "\n",
    "    p2 = tokenizer_p.texts_to_sequences(p2)\n",
    "\n",
    "    p2 = tf.keras.preprocessing.sequence.pad_sequences(p2, padding='post', maxlen=sent_length)\n",
    "\n",
    "    return model_name.predict(p2)\n",
    "\n",
    "def preciction_tf(model, data):\n",
    "    model_name = namestr(model,globals())[0]\n",
    "    predictions_test = pd.DataFrame(model.predict(data))\n",
    "    test_id = pd.DataFrame(predict[\"id\"])\n",
    "\n",
    "    submission = pd.concat([test_id, predictions_test],axis=1)\n",
    "    submission.columns = [\"id\",model_name]\n",
    "    submission.to_csv(\"out_{}.csv\".format(model_name),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1, x_test_1, y_train_1, y_test_1 = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "voc_size = 5000\n",
    "\n",
    "x_train_2=[one_hot(words,voc_size)for words in x_train_1] \n",
    "x_test_2=[one_hot(words,voc_size)for words in x_test_1] \n",
    "p_2=[one_hot(words,voc_size)for words in p] \n",
    "\n",
    "\n",
    "#tokenizer = Tokenizer(num_words=voc_size)\n",
    "#tokenizer.fit_on_texts(x_train_1)\n",
    "#\n",
    "#x_train_2 = tokenizer.texts_to_sequences(x_train_1)\n",
    "#x_test_2 = tokenizer.texts_to_sequences(x_test_1)\n",
    "#\n",
    "#tokenizer_p = Tokenizer(num_words=voc_size)\n",
    "#tokenizer_p.fit_on_texts(p)\n",
    "#p_2 = tokenizer_p.texts_to_sequences(p)\n",
    "\n",
    "sent_length=5000\n",
    "x_train_3 = tf.keras.preprocessing.sequence.pad_sequences(x_train_2, padding='post', maxlen=sent_length)\n",
    "x_test_3 = tf.keras.preprocessing.sequence.pad_sequences(x_test_2, padding='post', maxlen=sent_length)\n",
    "p_3 = tf.keras.preprocessing.sequence.pad_sequences(p_2, padding='post', maxlen=sent_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/34 [===============>..............] - ETA: 21s - loss: 1.5552 - accuracy: 0.4786"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ouyan\\Desktop\\Code\\FakeNews\\Machine Leaning\\ML_Combined.ipynb Cell 26'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ouyan/Desktop/Code/FakeNews/Machine%20Leaning/ML_Combined.ipynb#ch0000031?line=11'>12</a>\u001b[0m rnn\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m,optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ouyan/Desktop/Code/FakeNews/Machine%20Leaning/ML_Combined.ipynb#ch0000031?line=12'>13</a>\u001b[0m early_stop \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ouyan/Desktop/Code/FakeNews/Machine%20Leaning/ML_Combined.ipynb#ch0000031?line=13'>14</a>\u001b[0m history \u001b[39m=\u001b[39m rnn\u001b[39m.\u001b[39;49mfit(x_train_3, y_train_1, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, callbacks\u001b[39m=\u001b[39;49m[early_stop])\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(voc_size, 32))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "rnn = build_model()\n",
    "rnn.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = rnn.fit(x_train_3, y_train_1, epochs=50, validation_split=0.1, batch_size=64, shuffle=True, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using hyperameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "112               |?                 |dense\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://12c436f7-9377-4977-89ba-7058eb1ad79c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://12c436f7-9377-4977-89ba-7058eb1ad79c/assets\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All callbacks used during a search should be deep-copyable (since they are reused across trials). It is not possible to do `copy.deepcopy([<keras.callbacks.EarlyStopping object at 0x0000022E1BBF83A0>])`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:368\u001b[0m, in \u001b[0;36mTuner._deepcopy_callbacks\u001b[1;34m(self, callbacks)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 368\u001b[0m     callbacks \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39;49mdeepcopy(callbacks)\n\u001b[0;32m    369\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\copy.py:205\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m x:\n\u001b[1;32m--> 205\u001b[0m     append(deepcopy(a, memo))\n\u001b[0;32m    206\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[0;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\copy.py:270\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[39mif\u001b[39;00m deep:\n\u001b[1;32m--> 270\u001b[0m     state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[0;32m    271\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> 230\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    231\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     y \u001b[39m=\u001b[39m copier(memo)\n\u001b[0;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:337\u001b[0m, in \u001b[0;36mModel.__deepcopy__\u001b[1;34m(self, memo)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[1;32m--> 337\u001b[0m   new \u001b[39m=\u001b[39m pickle_utils\u001b[39m.\u001b[39;49mdeserialize_model_from_bytecode(\n\u001b[0;32m    338\u001b[0m       \u001b[39m*\u001b[39;49mpickle_utils\u001b[39m.\u001b[39;49mserialize_model_as_bytecode(\u001b[39mself\u001b[39;49m))\n\u001b[0;32m    339\u001b[0m   memo[\u001b[39mid\u001b[39m(\u001b[39mself\u001b[39m)] \u001b[39m=\u001b[39m new\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\site-packages\\keras\\saving\\pickle_utils.py:48\u001b[0m, in \u001b[0;36mdeserialize_model_from_bytecode\u001b[1;34m(serialized_model)\u001b[0m\n\u001b[0;32m     47\u001b[0m         f\u001b[39m.\u001b[39mwrite(archive\u001b[39m.\u001b[39mextractfile(name)\u001b[39m.\u001b[39mread())\n\u001b[1;32m---> 48\u001b[0m model \u001b[39m=\u001b[39m save_module\u001b[39m.\u001b[39;49mload_model(temp_dir)\n\u001b[0;32m     49\u001b[0m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mrmtree(temp_dir)\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:915\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    914\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 915\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m       \u001b[39mstr\u001b[39m(err) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m You may be trying to load on a different device \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mfrom the computational device. Consider setting the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    918\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    919\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mto the io_device such as \u001b[39m\u001b[39m'\u001b[39m\u001b[39m/job:localhost\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    920\u001b[0m root \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mget(\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ram://a7d2348b-f658-44fd-8279-b5b486668489/variables/variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ouyan\\Desktop\\Code\\FakeNews\\Machine Leaning\\ML_Combined.ipynb Cell 28'\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ouyan/Desktop/Code/FakeNews/Machine%20Leaning/ML_Combined.ipynb#ch0000067?line=11'>12</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ouyan/Desktop/Code/FakeNews/Machine%20Leaning/ML_Combined.ipynb#ch0000067?line=13'>14</a>\u001b[0m tuner \u001b[39m=\u001b[39m kt\u001b[39m.\u001b[39mRandomSearch(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ouyan/Desktop/Code/FakeNews/Machine%20Leaning/ML_Combined.ipynb#ch0000067?line=14'>15</a>\u001b[0m     build_model,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ouyan/Desktop/Code/FakeNews/Machine%20Leaning/ML_Combined.ipynb#ch0000067?line=15'>16</a>\u001b[0m     overwrite \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ouyan/Desktop/Code/FakeNews/Machine%20Leaning/ML_Combined.ipynb#ch0000067?line=16'>17</a>\u001b[0m     objective\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ouyan/Desktop/Code/FakeNews/Machine%20Leaning/ML_Combined.ipynb#ch0000067?line=17'>18</a>\u001b[0m     max_trials\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ouyan/Desktop/Code/FakeNews/Machine%20Leaning/ML_Combined.ipynb#ch0000067?line=19'>20</a>\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(x_train_3, y_train_1, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[early_stop])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ouyan/Desktop/Code/FakeNews/Machine%20Leaning/ML_Combined.ipynb#ch0000067?line=20'>21</a>\u001b[0m best_model \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mget_best_models()[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:179\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 179\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    180\u001b[0m \u001b[39m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[39mif\u001b[39;00m results \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:288\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[39mfor\u001b[39;00m execution \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecutions_per_trial):\n\u001b[0;32m    287\u001b[0m     copied_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mcopy(kwargs)\n\u001b[1;32m--> 288\u001b[0m     callbacks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_deepcopy_callbacks(original_callbacks)\n\u001b[0;32m    289\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_tensorboard_dir(callbacks, trial, execution)\n\u001b[0;32m    290\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(tuner_utils\u001b[39m.\u001b[39mTunerCallback(\u001b[39mself\u001b[39m, trial))\n",
      "File \u001b[1;32mc:\\Users\\ouyan\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:370\u001b[0m, in \u001b[0;36mTuner._deepcopy_callbacks\u001b[1;34m(self, callbacks)\u001b[0m\n\u001b[0;32m    368\u001b[0m     callbacks \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(callbacks)\n\u001b[0;32m    369\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m--> 370\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    371\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAll callbacks used during a search \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mshould be deep-copyable (since they are \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    373\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mreused across trials). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    374\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is not possible to do `copy.deepcopy(\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)`\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (callbacks,)\n\u001b[0;32m    375\u001b[0m     )\n\u001b[0;32m    376\u001b[0m \u001b[39mreturn\u001b[39;00m callbacks\n",
      "\u001b[1;31mValueError\u001b[0m: All callbacks used during a search should be deep-copyable (since they are reused across trials). It is not possible to do `copy.deepcopy([<keras.callbacks.EarlyStopping object at 0x0000022E1BBF83A0>])`"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(voc_size, 32))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)))\n",
    "    model.add(tf.keras.layers.Dense(hp.Int(\"dense\",16,128,16), activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    overwrite = True,\n",
    "    objective='val_loss',\n",
    "    max_trials=5)\n",
    "\n",
    "tuner.search(x_train_3, y_train_1, epochs=5, batch_size=64, validation_split=0.1)\n",
    "best_model = tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test loss, test acc\n",
    "rnn.evaluate(x_test_3, y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = str(\n",
    "    \"Not quite all the action is  . Peter Thiel, a founder of PayPal and Palantir who was the first outside investor in Facebook, spoke at the Republican convention in July. The New York Times reported on Saturday that Mr. Thiel is giving $1. 25 million to support Mr. Trump’s candidacy even as other supporters flee. (He also recently gave $1 million to a “super PAC” that supports Senator Rob Portman, the Republican freshman running for   in Ohio.) Getting involved in politics used to be seen as clashing with Silicon Valley’s value system: You transform the world by making problems obsolete, not solving them through Washington. Nor did entrepreneurs want to alienate whatever segment of customers did not agree with them politically. Such reticence is no longer in style here. “We’re a bunch of nerds not used to having a lot of limelight,” said Dave McClure, an investor who runs a tech incubator called 500 Startups.\"\n",
    "    )\n",
    "manual_predict_tf(rnn, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preciction_tf(rnn, p_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "x_train_ak = x_train_1.to_numpy()\n",
    "y_train_ak = y_train_1.to_numpy()\n",
    "x_test_ak = x_test_1.to_numpy()\n",
    "y_test_ak = y_test_1.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the text classifier.\n",
    "clf = ak.TextClassifier(\n",
    "    #max_trials=100,\n",
    "    #overwrite = False\n",
    ") \n",
    "# Feed the text classifier with training data.\n",
    "clf.fit(x_train_ak, y_train_ak, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test loss, test acc\n",
    "clf.evaluate(x_test_ak, y_test_ak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(clf.predict(p.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "import autokeras as ak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.keras.utils.get_file(\n",
    "    fname=\"aclImdb.tar.gz\",\n",
    "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
    "    extract=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n",
      "b'Zero Day leads you to think, even re-think why two'\n"
     ]
    }
   ],
   "source": [
    "# set path to dataset\n",
    "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
    "\n",
    "classes = [\"pos\", \"neg\"]\n",
    "train_data = load_files(\n",
    "    os.path.join(IMDB_DATADIR, \"train\"), shuffle=True, categories=classes\n",
    ")\n",
    "test_data = load_files(\n",
    "    os.path.join(IMDB_DATADIR, \"test\"), shuffle=False, categories=classes\n",
    ")\n",
    "\n",
    "x_train = np.array(train_data.data)\n",
    "y_train = np.array(train_data.target)\n",
    "x_test = np.array(test_data.data)\n",
    "y_test = np.array(test_data.target)\n",
    "\n",
    "print(x_train.shape)  # (25000,)\n",
    "print(y_train.shape)  # (25000, 1)\n",
    "print(x_train[0][:50])  # this film was just brilliant casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 38s]\n",
      "val_loss: 0.3694274425506592\n",
      "\n",
      "Best val_loss So Far: 0.3694274425506592\n",
      "Total elapsed time: 00h 00m 38s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 4s 18ms/step - loss: 0.6855 - accuracy: 0.5282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\text_classifier\\best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\text_classifier\\best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 7s 9ms/step\n",
      "782/782 [==============================] - 5s 7ms/step\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 0.6375 - accuracy: 0.6081\n",
      "[0.6374950408935547, 0.6080800294876099]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the text classifier.\n",
    "clf = ak.TextClassifier(\n",
    "    overwrite=True, max_trials=1\n",
    ")  # It only tries 1 model as a quick demo.\n",
    "# Feed the text classifier with training data.\n",
    "clf.fit(x_train, y_train)\n",
    "# Predict with the best model.\n",
    "predicted_y = clf.predict(x_test)\n",
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    # Split the training data and use the last 15% as validation data.\n",
    "    validation_split=0.15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 5000\n",
    "x_val = x_train[split:]\n",
    "y_val = y_train[split:]\n",
    "x_train = x_train[:split]\n",
    "y_train = y_train[:split]\n",
    "clf.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    # Use your own validation set.\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "91750c2a53790ed423a273a56ec734ea7db5090134fb92fb4e4bee44fe7b9fce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
